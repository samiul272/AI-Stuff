{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenBanglaCapsNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/samiul272/AI-Stuff/blob/master/OpenBanglaCapsNet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WvTmY9jh_QfV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*This code is adapted for use in Google Colaboratory from Kevin Mader's [Capsulenet implementation](https://www.kaggle.com/kmader/capsulenet-on-mnist) which in turn is adapted from Xifeng Guo's github [code](https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py). These codes are based on Sara Sabour's paper [Dynamic Routing Between Capsules](https://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf).*"
      ]
    },
    {
      "metadata": {
        "id": "E6tfXAMw-WzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**First we install fuse drive. This will enable us to use our google drive data directly in colab without needing to get the Id  every time**"
      ]
    },
    {
      "metadata": {
        "id": "SLN_b1463kq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2278
        },
        "outputId": "7bc4c326-22d4-4c8d-940b-0683b3917c65"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 16712 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.1_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.1) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.1) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpn2zp7lcu/pubring.gpg' created\n",
            "gpg: /tmp/tmpn2zp7lcu/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 18120 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoZfdiuSBRfT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Next we get our tokens. You will get a link that you'd need to follow and sign in to your google account and allow access.**"
      ]
    },
    {
      "metadata": {
        "id": "zomeqM1b4C6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbgT2caxBvDd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We will do the same for the fuse library**"
      ]
    },
    {
      "metadata": {
        "id": "_bWCL1dK5jwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ff255cbd-ef0f-4f73-f4e7-30999f16b99d"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3MJORJcOCIXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Next we make directory drive. This will point to your drive home page. You can change the directory by using *ls* command and see what is inside **"
      ]
    },
    {
      "metadata": {
        "id": "VFwo_fFl4ZfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "13f81a6e-7988-4baf-d262-6e799017d169"
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive -o nonempty\n",
        "\n",
        "print('Files in Drive:')\n",
        "!ls drive/Datasets/Final_DB"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in Drive:\n",
            "capsulelayers.py\t testing-a\ttesting-e\ttraining-c\n",
            "capsulelayers.pyc\t testing-a.csv\ttesting-e.csv\ttraining-c.csv\n",
            "capsulenet.py\t\t testing-b\ttesting-f\ttraining-d\n",
            "loaders.py\t\t testing-b.csv\ttesting-f.csv\ttraining-d.csv\n",
            "loaders.pyc\t\t testing-c\ttraining-a\ttraining-e\n",
            "OpenBanglaCapsNet.ipynb  testing-c.csv\ttraining-a.csv\ttraining-e.csv\n",
            "__pycache__\t\t testing-d\ttraining-b\tutils.py\n",
            "stats.xlsx\t\t testing-d.csv\ttraining-b.csv\tutils.pyc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NNpBWfi5CHV0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now we get to the actual code work. We start by importing all the things we need.**"
      ]
    },
    {
      "metadata": {
        "id": "yJ2D7mxACf9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa32e120-bcd1-4f37-aebe-1c0b809d1533"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NaMlIpciD6gP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Next the special layers for capsule net are defined**"
      ]
    },
    {
      "metadata": {
        "id": "8tU3LLmEDRGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss\n",
        "    inputs: shape=[dim_1, ..., dim_{n-1}, dim_n]\n",
        "    output: shape=[dim_1, ..., dim_{n-1}]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, d1, d2] by the max value in axis=1.\n",
        "    Output shape: [None, d2]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # use true label to select target capsule, shape=[batch_size, num_capsule]\n",
        "        if type(inputs) is list:  # true label is provided with shape = [batch_size, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of vectors of capsules\n",
        "            x = inputs\n",
        "            # Enlarge the range of values in x to make max(new_x)=1 and others < 0\n",
        "            x = (x - K.max(x, 1, True)) / K.epsilon() + 1\n",
        "            mask = K.clip(x, 0, 1)  # the max value in x clipped to 1 and other to 0\n",
        "\n",
        "        # masked inputs, shape = [batch_size, dim_vector]\n",
        "        inputs_masked = K.batch_dot(inputs, mask, [1, 1])\n",
        "        return inputs_masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][-1]])\n",
        "        else:\n",
        "            return tuple([None, input_shape[-1]])\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm)\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_vector] and output shape = \\\n",
        "    [None, num_capsule, dim_vector]. For Dense Layer, input_dim_vector = dim_vector = 1.\n",
        "    \n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_vector: dimension of the output vectors of the capsules in this layer\n",
        "    :param num_routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_vector, num_routing=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_vector = dim_vector\n",
        "        self.num_routing = num_routing\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_vector]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_vector = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dim_vector],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        # Coupling coefficient. The redundant dimensions are just to facilitate subsequent matrix calculation.\n",
        "        self.bias = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1],\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    name='bias',\n",
        "                                    trainable=False)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_vector]\n",
        "        # Expand dims to [None, input_num_capsule, 1, 1, input_dim_vector]\n",
        "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # Now it has shape = [None, input_num_capsule, num_capsule, 1, input_dim_vector]\n",
        "        inputs_tiled = K.tile(inputs_expand, [1, 1, self.num_capsule, 1, 1])\n",
        "\n",
        "        \"\"\"  \n",
        "        # Compute `inputs * W` by expanding the first dim of W. More time-consuming and need batch_size.\n",
        "        # Now W has shape  = [batch_size, input_num_capsule, num_capsule, input_dim_vector, dim_vector]\n",
        "        w_tiled = K.tile(K.expand_dims(self.W, 0), [self.batch_size, 1, 1, 1, 1])\n",
        "        \n",
        "        # Transformed vectors, inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
        "        inputs_hat = K.batch_dot(inputs_tiled, w_tiled, [4, 3])\n",
        "        \"\"\"\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0. This is faster but requires Tensorflow.\n",
        "        # inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
        "        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n",
        "                             elems=inputs_tiled,\n",
        "                             initializer=K.zeros([self.input_num_capsule, self.num_capsule, 1, self.dim_vector]))\n",
        "        \"\"\"\n",
        "        # Routing algorithm V1. Use tf.while_loop in a dynamic way.\n",
        "        def body(i, b, outputs):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
        "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
        "            b = b + K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "            return [i-1, b, outputs]\n",
        "\n",
        "        cond = lambda i, b, inputs_hat: i > 0\n",
        "        loop_vars = [K.constant(self.num_routing), self.bias, K.sum(inputs_hat, 1, keepdims=True)]\n",
        "        _, _, outputs = tf.while_loop(cond, body, loop_vars)\n",
        "        \"\"\"\n",
        "        # Routing algorithm V2. Use iteration. V2 and V1 both work without much difference on performance\n",
        "        assert self.num_routing > 0, 'The num_routing should be > 0.'\n",
        "        for i in range(self.num_routing):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
        "            # outputs.shape=[None, 1, num_capsule, 1, dim_vector]\n",
        "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
        "\n",
        "            # last iteration needs not compute bias which will not be passed to the graph any more anyway.\n",
        "            if i != self.num_routing - 1:\n",
        "                # self.bias = K.update_add(self.bias, K.sum(inputs_hat * outputs, [0, -1], keepdims=True))\n",
        "                self.bias += K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "            # tf.summary.histogram('BigBee', self.bias)  # for debugging\n",
        "        return K.reshape(outputs, [-1, self.num_capsule, self.dim_vector])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_vector])\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_vector: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_vector]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n",
        "    return layers.Lambda(squash)(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPKPB9mOEDec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CapsNet is the actual model. We define it here. Unlike training a regular machine learning model, the input-output relation in capsnet is not defined by the standard $X$â$$ relation but rather an $(X,y)$ â $(y,X)$model meaning it attempts to predict the class from the image, and then at the same time, using the same capsule reconstruct the image from the class. This follows the conditional generative adverserial network model and the task of reconstructing the model helps the model understand the image better.**y "
      ]
    },
    {
      "metadata": {
        "id": "OTP-NqD-DYI-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import layers, models\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "def CapsNet(input_shape, n_class, num_routing):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 4d, [None, width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param num_routing: number of routing iterations\n",
        "    :return: A Keras Model with 2 inputs and 2 outputs\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_vector]\n",
        "    primarycaps = PrimaryCap(conv1, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_vector=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='out_caps')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer.\n",
        "    x_recon = layers.Dense(512, activation='relu')(masked)\n",
        "    x_recon = layers.Dense(1024, activation='relu')(x_recon)\n",
        "    x_recon = layers.Dense(784, activation='sigmoid')(x_recon)\n",
        "    x_recon = layers.Reshape(target_shape=[28, 28, 1], name='out_recon')(x_recon)\n",
        "\n",
        "    # two-input-two-output keras Model\n",
        "    return models.Model([x, y], [out_caps, x_recon])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5KLiBvSWF7cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**This defines the loss function**"
      ]
    },
    {
      "metadata": {
        "id": "OOEIX9_9DgIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHS8TqknGEBz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We take a look at the summary of the model. Around 8 million parameters to optimize. This  will increase exponentially if you use lager images **"
      ]
    },
    {
      "metadata": {
        "id": "ddavd8NkDj8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "21c8facc-ac90-4a5c-8652-3e0c8c029131"
      },
      "cell_type": "code",
      "source": [
        "model = CapsNet(input_shape=[28, 28, 1],\n",
        "                n_class=10,\n",
        "                num_routing=3)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-8daadbc5443a>:132: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1152, 8)      0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1152, 8)      0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (None, 10, 16)       1486080     lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_1 (Mask)                   (None, 16)           0           digitcaps[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          8704        mask_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         525312      dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 784)          803600      dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "out_caps (Length)               (None, 10)           0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "out_recon (Reshape)             (None, 28, 28, 1)    0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,153,360\n",
            "Trainable params: 8,141,840\n",
            "Non-trainable params: 11,520\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m4CSgDJfGj64",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We split the train data into training and validation sets using sklearn's *train_test_split* function. However it will be best to slit this in a way that best makes validation and train sets uncorrelated. I converted the dataset beforehand into hd5 format as drive takes a long time to directly access individual files.**"
      ]
    },
    {
      "metadata": {
        "id": "ytP-7D7CEMd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import h5py\n",
        "\n",
        "with h5py.File('drive/Datasets/traindata28.h5', 'r') as hf:\n",
        "    X = hf['Images'][:]\n",
        "    Y = hf['Labels'][:]\n",
        "    \n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y)\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "y_train = to_categorical(y_train.astype('float32'))\n",
        "y_test = to_categorical(y_test.astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DCq4plsHDYB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now we define the training function**"
      ]
    },
    {
      "metadata": {
        "id": "vX5J_12WF8zK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, data, epoch_size_frac=1.0,num=0):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger('log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint('weights-{epoch:02d}.h5',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., 0.0005],\n",
        "                  metrics={'out_caps': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint])\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------------------Begin: Training with data augmentation -----------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
        "    model.fit_generator(generator=train_generator(x_train, y_train, 64, 0.1),\n",
        "                        steps_per_epoch=int(epoch_size_frac*y_train.shape[0] / 64),\n",
        "                        epochs=5,\n",
        "                        validation_data=[[x_test, y_test], [y_test, x_test]])\n",
        "    # -----------------------------------End: Training with data augmentation -----------------------------------#\n",
        "\n",
        "    model.save_weights('drive/Datasets/model.h5')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QtF9ewY3HbTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Since this is a cloud based service that is given \"$free$\" it is best to periodically save your models during training. Remember colab will not let you occupy a virtual machine for more than 6 hours and has the occasional tendency to disconnect in the middle of long processes **"
      ]
    },
    {
      "metadata": {
        "id": "zAd5PrqdGj4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1907
        },
        "outputId": "177ef0b0-265b-47cc-ac88-a7095209680c"
      },
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "    print(i)\n",
        "    model.load_weights('drive/Datasets/model.h5')\n",
        "    train(model=model, data=((x_train, y_train), (x_test, y_test)), num = i)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1/5\n",
            " 653/1120 [================>.............] - ETA: 2:02 - loss: 0.1011 - out_caps_loss: 0.1011 - out_recon_loss: 0.0377 - out_caps_acc: 0.8975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.1010 - out_caps_loss: 0.1010 - out_recon_loss: 0.0376 - out_caps_acc: 0.8975 - val_loss: 0.0894 - val_out_caps_loss: 0.0894 - val_out_recon_loss: 0.0448 - val_out_caps_acc: 0.9156\n",
            "Epoch 2/5\n",
            "  84/1120 [=>............................] - ETA: 4:26 - loss: 0.1069 - out_caps_loss: 0.1068 - out_recon_loss: 0.0368 - out_caps_acc: 0.9022"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 792/1120 [====================>.........] - ETA: 1:25 - loss: 0.0969 - out_caps_loss: 0.0968 - out_recon_loss: 0.0369 - out_caps_acc: 0.9020"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0963 - out_caps_loss: 0.0963 - out_recon_loss: 0.0370 - out_caps_acc: 0.9030 - val_loss: 0.0857 - val_out_caps_loss: 0.0857 - val_out_recon_loss: 0.0445 - val_out_caps_acc: 0.9124\n",
            "Epoch 3/5\n",
            " 133/1120 [==>...........................] - ETA: 4:14 - loss: 0.1107 - out_caps_loss: 0.1107 - out_recon_loss: 0.0371 - out_caps_acc: 0.8832"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 841/1120 [=====================>........] - ETA: 1:12 - loss: 0.0928 - out_caps_loss: 0.0928 - out_recon_loss: 0.0365 - out_caps_acc: 0.9042"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 273ms/step - loss: 0.0915 - out_caps_loss: 0.0914 - out_recon_loss: 0.0365 - out_caps_acc: 0.9055 - val_loss: 0.0733 - val_out_caps_loss: 0.0732 - val_out_recon_loss: 0.0438 - val_out_caps_acc: 0.9265\n",
            "Epoch 4/5\n",
            " 150/1120 [===>..........................] - ETA: 4:08 - loss: 0.1019 - out_caps_loss: 0.1019 - out_recon_loss: 0.0354 - out_caps_acc: 0.8988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 858/1120 [=====================>........] - ETA: 1:07 - loss: 0.0887 - out_caps_loss: 0.0887 - out_recon_loss: 0.0358 - out_caps_acc: 0.9097"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 305s 273ms/step - loss: 0.0875 - out_caps_loss: 0.0875 - out_recon_loss: 0.0358 - out_caps_acc: 0.9116 - val_loss: 0.0812 - val_out_caps_loss: 0.0812 - val_out_recon_loss: 0.0430 - val_out_caps_acc: 0.9177\n",
            "Epoch 5/5\n",
            " 157/1120 [===>..........................] - ETA: 4:08 - loss: 0.0854 - out_caps_loss: 0.0854 - out_recon_loss: 0.0357 - out_caps_acc: 0.9181"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 865/1120 [======================>.......] - ETA: 1:05 - loss: 0.0885 - out_caps_loss: 0.0885 - out_recon_loss: 0.0354 - out_caps_acc: 0.9118"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 305s 272ms/step - loss: 0.0903 - out_caps_loss: 0.0903 - out_recon_loss: 0.0353 - out_caps_acc: 0.9091 - val_loss: 0.0806 - val_out_caps_loss: 0.0806 - val_out_recon_loss: 0.0424 - val_out_caps_acc: 0.9205\n",
            "1\n",
            "Epoch 1/5\n",
            " 157/1120 [===>..........................] - ETA: 4:14 - loss: 0.0888 - out_caps_loss: 0.0888 - out_recon_loss: 0.0346 - out_caps_acc: 0.9109"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0810 - out_caps_loss: 0.0810 - out_recon_loss: 0.0350 - out_caps_acc: 0.9181"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0823 - out_caps_loss: 0.0823 - out_recon_loss: 0.0351 - out_caps_acc: 0.9168 - val_loss: 0.0783 - val_out_caps_loss: 0.0782 - val_out_recon_loss: 0.0423 - val_out_caps_acc: 0.9242\n",
            "Epoch 2/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0938 - out_caps_loss: 0.0938 - out_recon_loss: 0.0351 - out_caps_acc: 0.9034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0861 - out_caps_loss: 0.0861 - out_recon_loss: 0.0351 - out_caps_acc: 0.9109"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 275ms/step - loss: 0.0841 - out_caps_loss: 0.0841 - out_recon_loss: 0.0350 - out_caps_acc: 0.9138 - val_loss: 0.0667 - val_out_caps_loss: 0.0667 - val_out_recon_loss: 0.0421 - val_out_caps_acc: 0.9346\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:06 - loss: 0.0951 - out_caps_loss: 0.0951 - out_recon_loss: 0.0337 - out_caps_acc: 0.9031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0840 - out_caps_loss: 0.0839 - out_recon_loss: 0.0345 - out_caps_acc: 0.9149"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 273ms/step - loss: 0.0835 - out_caps_loss: 0.0835 - out_recon_loss: 0.0345 - out_caps_acc: 0.9148 - val_loss: 0.0713 - val_out_caps_loss: 0.0713 - val_out_recon_loss: 0.0418 - val_out_caps_acc: 0.9296\n",
            "Epoch 4/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0913 - out_caps_loss: 0.0913 - out_recon_loss: 0.0355 - out_caps_acc: 0.9091"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0785 - out_caps_loss: 0.0784 - out_recon_loss: 0.0343 - out_caps_acc: 0.9203"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 305s 273ms/step - loss: 0.0785 - out_caps_loss: 0.0785 - out_recon_loss: 0.0343 - out_caps_acc: 0.9203 - val_loss: 0.0684 - val_out_caps_loss: 0.0683 - val_out_recon_loss: 0.0414 - val_out_caps_acc: 0.9343\n",
            "Epoch 5/5\n",
            " 159/1120 [===>..........................] - ETA: 4:07 - loss: 0.0718 - out_caps_loss: 0.0718 - out_recon_loss: 0.0334 - out_caps_acc: 0.9290"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0748 - out_caps_loss: 0.0748 - out_recon_loss: 0.0337 - out_caps_acc: 0.9252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 305s 272ms/step - loss: 0.0745 - out_caps_loss: 0.0745 - out_recon_loss: 0.0337 - out_caps_acc: 0.9252 - val_loss: 0.0679 - val_out_caps_loss: 0.0679 - val_out_recon_loss: 0.0415 - val_out_caps_acc: 0.9332\n",
            "2\n",
            "Epoch 1/5\n",
            " 157/1120 [===>..........................] - ETA: 4:14 - loss: 0.0754 - out_caps_loss: 0.0753 - out_recon_loss: 0.0335 - out_caps_acc: 0.9242"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 865/1120 [======================>.......] - ETA: 1:06 - loss: 0.0780 - out_caps_loss: 0.0780 - out_recon_loss: 0.0335 - out_caps_acc: 0.9214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0762 - out_caps_loss: 0.0761 - out_recon_loss: 0.0337 - out_caps_acc: 0.9235 - val_loss: 0.0977 - val_out_caps_loss: 0.0977 - val_out_recon_loss: 0.0413 - val_out_caps_acc: 0.9025\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0761 - out_caps_loss: 0.0761 - out_recon_loss: 0.0341 - out_caps_acc: 0.9232"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0719 - out_caps_loss: 0.0718 - out_recon_loss: 0.0337 - out_caps_acc: 0.9274"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0715 - out_caps_loss: 0.0715 - out_recon_loss: 0.0336 - out_caps_acc: 0.9273 - val_loss: 0.0629 - val_out_caps_loss: 0.0629 - val_out_recon_loss: 0.0410 - val_out_caps_acc: 0.9370\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0724 - out_caps_loss: 0.0724 - out_recon_loss: 0.0328 - out_caps_acc: 0.9303"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0701 - out_caps_loss: 0.0701 - out_recon_loss: 0.0332 - out_caps_acc: 0.9302"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0698 - out_caps_loss: 0.0698 - out_recon_loss: 0.0333 - out_caps_acc: 0.9302 - val_loss: 0.0646 - val_out_caps_loss: 0.0646 - val_out_recon_loss: 0.0407 - val_out_caps_acc: 0.9379\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0709 - out_caps_loss: 0.0709 - out_recon_loss: 0.0331 - out_caps_acc: 0.9296"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0687 - out_caps_loss: 0.0687 - out_recon_loss: 0.0329 - out_caps_acc: 0.9312"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0682 - out_caps_loss: 0.0682 - out_recon_loss: 0.0330 - out_caps_acc: 0.9324 - val_loss: 0.0602 - val_out_caps_loss: 0.0602 - val_out_recon_loss: 0.0408 - val_out_caps_acc: 0.9398\n",
            "Epoch 5/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0842 - out_caps_loss: 0.0842 - out_recon_loss: 0.0345 - out_caps_acc: 0.9227"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0710 - out_caps_loss: 0.0710 - out_recon_loss: 0.0332 - out_caps_acc: 0.9305"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 274ms/step - loss: 0.0698 - out_caps_loss: 0.0698 - out_recon_loss: 0.0332 - out_caps_acc: 0.9312 - val_loss: 0.0630 - val_out_caps_loss: 0.0630 - val_out_recon_loss: 0.0408 - val_out_caps_acc: 0.9381\n",
            "3\n",
            "Epoch 1/5\n",
            " 158/1120 [===>..........................] - ETA: 4:14 - loss: 0.0679 - out_caps_loss: 0.0679 - out_recon_loss: 0.0330 - out_caps_acc: 0.9291"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 866/1120 [======================>.......] - ETA: 1:06 - loss: 0.0660 - out_caps_loss: 0.0659 - out_recon_loss: 0.0327 - out_caps_acc: 0.9335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0668 - out_caps_loss: 0.0668 - out_recon_loss: 0.0328 - out_caps_acc: 0.9330 - val_loss: 0.0963 - val_out_caps_loss: 0.0963 - val_out_recon_loss: 0.0408 - val_out_caps_acc: 0.9085\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:08 - loss: 0.0700 - out_caps_loss: 0.0700 - out_recon_loss: 0.0316 - out_caps_acc: 0.9296"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0643 - out_caps_loss: 0.0643 - out_recon_loss: 0.0328 - out_caps_acc: 0.9355"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0641 - out_caps_loss: 0.0641 - out_recon_loss: 0.0327 - out_caps_acc: 0.9361 - val_loss: 0.0617 - val_out_caps_loss: 0.0617 - val_out_recon_loss: 0.0403 - val_out_caps_acc: 0.9404\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0601 - out_caps_loss: 0.0601 - out_recon_loss: 0.0321 - out_caps_acc: 0.9404"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0624 - out_caps_loss: 0.0624 - out_recon_loss: 0.0327 - out_caps_acc: 0.9377"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0621 - out_caps_loss: 0.0621 - out_recon_loss: 0.0325 - out_caps_acc: 0.9386 - val_loss: 0.0659 - val_out_caps_loss: 0.0659 - val_out_recon_loss: 0.0399 - val_out_caps_acc: 0.9375\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0625 - out_caps_loss: 0.0625 - out_recon_loss: 0.0322 - out_caps_acc: 0.9401"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0614 - out_caps_loss: 0.0613 - out_recon_loss: 0.0325 - out_caps_acc: 0.9394"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0618 - out_caps_loss: 0.0618 - out_recon_loss: 0.0324 - out_caps_acc: 0.9391 - val_loss: 0.0549 - val_out_caps_loss: 0.0548 - val_out_recon_loss: 0.0407 - val_out_caps_acc: 0.9462\n",
            "Epoch 5/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0602 - out_caps_loss: 0.0602 - out_recon_loss: 0.0336 - out_caps_acc: 0.9393"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0620 - out_caps_loss: 0.0620 - out_recon_loss: 0.0323 - out_caps_acc: 0.9390"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0610 - out_caps_loss: 0.0610 - out_recon_loss: 0.0324 - out_caps_acc: 0.9397 - val_loss: 0.0577 - val_out_caps_loss: 0.0576 - val_out_recon_loss: 0.0401 - val_out_caps_acc: 0.9473\n",
            "4\n",
            "Epoch 1/5\n",
            " 158/1120 [===>..........................] - ETA: 4:16 - loss: 0.0621 - out_caps_loss: 0.0620 - out_recon_loss: 0.0320 - out_caps_acc: 0.9388"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 866/1120 [======================>.......] - ETA: 1:06 - loss: 0.0597 - out_caps_loss: 0.0597 - out_recon_loss: 0.0321 - out_caps_acc: 0.9413"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 310s 277ms/step - loss: 0.0594 - out_caps_loss: 0.0593 - out_recon_loss: 0.0321 - out_caps_acc: 0.9416 - val_loss: 0.0587 - val_out_caps_loss: 0.0587 - val_out_recon_loss: 0.0403 - val_out_caps_acc: 0.9407\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:08 - loss: 0.0657 - out_caps_loss: 0.0657 - out_recon_loss: 0.0312 - out_caps_acc: 0.9396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0600 - out_caps_loss: 0.0600 - out_recon_loss: 0.0320 - out_caps_acc: 0.9412"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0602 - out_caps_loss: 0.0602 - out_recon_loss: 0.0319 - out_caps_acc: 0.9411 - val_loss: 0.0676 - val_out_caps_loss: 0.0676 - val_out_recon_loss: 0.0404 - val_out_caps_acc: 0.9366\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:09 - loss: 0.0599 - out_caps_loss: 0.0598 - out_recon_loss: 0.0323 - out_caps_acc: 0.9390"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0609 - out_caps_loss: 0.0609 - out_recon_loss: 0.0318 - out_caps_acc: 0.9405"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 275ms/step - loss: 0.0659 - out_caps_loss: 0.0659 - out_recon_loss: 0.0319 - out_caps_acc: 0.9351 - val_loss: 0.0815 - val_out_caps_loss: 0.0815 - val_out_recon_loss: 0.0399 - val_out_caps_acc: 0.9189\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0896 - out_caps_loss: 0.0896 - out_recon_loss: 0.0317 - out_caps_acc: 0.9117"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0783 - out_caps_loss: 0.0783 - out_recon_loss: 0.0318 - out_caps_acc: 0.9216"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0762 - out_caps_loss: 0.0762 - out_recon_loss: 0.0318 - out_caps_acc: 0.9240 - val_loss: 0.0662 - val_out_caps_loss: 0.0662 - val_out_recon_loss: 0.0400 - val_out_caps_acc: 0.9350\n",
            "Epoch 5/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0920 - out_caps_loss: 0.0920 - out_recon_loss: 0.0317 - out_caps_acc: 0.9072"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0635 - out_caps_loss: 0.0635 - out_recon_loss: 0.0317 - out_caps_acc: 0.9372"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0626 - out_caps_loss: 0.0626 - out_recon_loss: 0.0318 - out_caps_acc: 0.9381 - val_loss: 0.0594 - val_out_caps_loss: 0.0594 - val_out_recon_loss: 0.0398 - val_out_caps_acc: 0.9407\n",
            "5\n",
            "Epoch 1/5\n",
            " 157/1120 [===>..........................] - ETA: 4:16 - loss: 0.0568 - out_caps_loss: 0.0568 - out_recon_loss: 0.0309 - out_caps_acc: 0.9458"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 865/1120 [======================>.......] - ETA: 1:06 - loss: 0.0582 - out_caps_loss: 0.0582 - out_recon_loss: 0.0315 - out_caps_acc: 0.9432"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0582 - out_caps_loss: 0.0582 - out_recon_loss: 0.0316 - out_caps_acc: 0.9431 - val_loss: 0.0568 - val_out_caps_loss: 0.0567 - val_out_recon_loss: 0.0400 - val_out_caps_acc: 0.9457\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:08 - loss: 0.0626 - out_caps_loss: 0.0626 - out_recon_loss: 0.0310 - out_caps_acc: 0.9403"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0570 - out_caps_loss: 0.0570 - out_recon_loss: 0.0316 - out_caps_acc: 0.9446"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 273ms/step - loss: 0.0565 - out_caps_loss: 0.0564 - out_recon_loss: 0.0316 - out_caps_acc: 0.9454 - val_loss: 0.0534 - val_out_caps_loss: 0.0534 - val_out_recon_loss: 0.0398 - val_out_caps_acc: 0.9470\n",
            "Epoch 3/5\n",
            " 159/1120 [===>..........................] - ETA: 4:08 - loss: 0.0595 - out_caps_loss: 0.0595 - out_recon_loss: 0.0315 - out_caps_acc: 0.9422"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0567 - out_caps_loss: 0.0567 - out_recon_loss: 0.0313 - out_caps_acc: 0.9437"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 273ms/step - loss: 0.0563 - out_caps_loss: 0.0563 - out_recon_loss: 0.0314 - out_caps_acc: 0.9443 - val_loss: 0.0518 - val_out_caps_loss: 0.0518 - val_out_recon_loss: 0.0392 - val_out_caps_acc: 0.9490\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:07 - loss: 0.0527 - out_caps_loss: 0.0527 - out_recon_loss: 0.0319 - out_caps_acc: 0.9479"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0547 - out_caps_loss: 0.0547 - out_recon_loss: 0.0311 - out_caps_acc: 0.9456"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 274ms/step - loss: 0.0544 - out_caps_loss: 0.0544 - out_recon_loss: 0.0313 - out_caps_acc: 0.9461 - val_loss: 0.0569 - val_out_caps_loss: 0.0569 - val_out_recon_loss: 0.0398 - val_out_caps_acc: 0.9470\n",
            "Epoch 5/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0529 - out_caps_loss: 0.0528 - out_recon_loss: 0.0318 - out_caps_acc: 0.9483"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0546 - out_caps_loss: 0.0546 - out_recon_loss: 0.0313 - out_caps_acc: 0.9468"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 306s 273ms/step - loss: 0.0542 - out_caps_loss: 0.0542 - out_recon_loss: 0.0312 - out_caps_acc: 0.9471 - val_loss: 0.0507 - val_out_caps_loss: 0.0506 - val_out_recon_loss: 0.0403 - val_out_caps_acc: 0.9503\n",
            "6\n",
            "Epoch 1/5\n",
            " 158/1120 [===>..........................] - ETA: 4:16 - loss: 0.0541 - out_caps_loss: 0.0541 - out_recon_loss: 0.0306 - out_caps_acc: 0.9481"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 866/1120 [======================>.......] - ETA: 1:06 - loss: 0.0532 - out_caps_loss: 0.0532 - out_recon_loss: 0.0312 - out_caps_acc: 0.9486"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 309s 276ms/step - loss: 0.0532 - out_caps_loss: 0.0532 - out_recon_loss: 0.0312 - out_caps_acc: 0.9482 - val_loss: 0.0543 - val_out_caps_loss: 0.0542 - val_out_recon_loss: 0.0397 - val_out_caps_acc: 0.9447\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0770 - out_caps_loss: 0.0770 - out_recon_loss: 0.0311 - out_caps_acc: 0.9264"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0564 - out_caps_loss: 0.0563 - out_recon_loss: 0.0309 - out_caps_acc: 0.9461"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0555 - out_caps_loss: 0.0554 - out_recon_loss: 0.0311 - out_caps_acc: 0.9465 - val_loss: 0.0572 - val_out_caps_loss: 0.0572 - val_out_recon_loss: 0.0395 - val_out_caps_acc: 0.9456\n",
            "Epoch 3/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0504 - out_caps_loss: 0.0504 - out_recon_loss: 0.0307 - out_caps_acc: 0.9525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0518 - out_caps_loss: 0.0518 - out_recon_loss: 0.0309 - out_caps_acc: 0.9497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0537 - out_caps_loss: 0.0537 - out_recon_loss: 0.0310 - out_caps_acc: 0.9482 - val_loss: 0.0600 - val_out_caps_loss: 0.0600 - val_out_recon_loss: 0.0394 - val_out_caps_acc: 0.9402\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0640 - out_caps_loss: 0.0640 - out_recon_loss: 0.0298 - out_caps_acc: 0.9392"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0561 - out_caps_loss: 0.0561 - out_recon_loss: 0.0308 - out_caps_acc: 0.9467"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0559 - out_caps_loss: 0.0559 - out_recon_loss: 0.0309 - out_caps_acc: 0.9469 - val_loss: 0.0578 - val_out_caps_loss: 0.0578 - val_out_recon_loss: 0.0396 - val_out_caps_acc: 0.9430\n",
            "Epoch 5/5\n",
            " 159/1120 [===>..........................] - ETA: 4:08 - loss: 0.0562 - out_caps_loss: 0.0562 - out_recon_loss: 0.0312 - out_caps_acc: 0.9463"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0542 - out_caps_loss: 0.0542 - out_recon_loss: 0.0308 - out_caps_acc: 0.9474"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0545 - out_caps_loss: 0.0544 - out_recon_loss: 0.0308 - out_caps_acc: 0.9473 - val_loss: 0.0496 - val_out_caps_loss: 0.0495 - val_out_recon_loss: 0.0393 - val_out_caps_acc: 0.9520\n",
            "7\n",
            "Epoch 1/5\n",
            " 157/1120 [===>..........................] - ETA: 4:18 - loss: 0.0512 - out_caps_loss: 0.0512 - out_recon_loss: 0.0308 - out_caps_acc: 0.9517"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 865/1120 [======================>.......] - ETA: 1:06 - loss: 0.0518 - out_caps_loss: 0.0518 - out_recon_loss: 0.0308 - out_caps_acc: 0.9488"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0515 - out_caps_loss: 0.0514 - out_recon_loss: 0.0308 - out_caps_acc: 0.9497 - val_loss: 0.0528 - val_out_caps_loss: 0.0528 - val_out_recon_loss: 0.0390 - val_out_caps_acc: 0.9509\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:08 - loss: 0.0525 - out_caps_loss: 0.0525 - out_recon_loss: 0.0307 - out_caps_acc: 0.9476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0513 - out_caps_loss: 0.0513 - out_recon_loss: 0.0307 - out_caps_acc: 0.9488"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0534 - out_caps_loss: 0.0534 - out_recon_loss: 0.0308 - out_caps_acc: 0.9472 - val_loss: 0.0539 - val_out_caps_loss: 0.0539 - val_out_recon_loss: 0.0393 - val_out_caps_acc: 0.9474\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0516 - out_caps_loss: 0.0516 - out_recon_loss: 0.0313 - out_caps_acc: 0.9497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0515 - out_caps_loss: 0.0515 - out_recon_loss: 0.0307 - out_caps_acc: 0.9500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0512 - out_caps_loss: 0.0512 - out_recon_loss: 0.0307 - out_caps_acc: 0.9505 - val_loss: 0.0518 - val_out_caps_loss: 0.0517 - val_out_recon_loss: 0.0394 - val_out_caps_acc: 0.9501\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:08 - loss: 0.0969 - out_caps_loss: 0.0969 - out_recon_loss: 0.0299 - out_caps_acc: 0.9053"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0701 - out_caps_loss: 0.0701 - out_recon_loss: 0.0304 - out_caps_acc: 0.9320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0659 - out_caps_loss: 0.0659 - out_recon_loss: 0.0305 - out_caps_acc: 0.9357 - val_loss: 0.0481 - val_out_caps_loss: 0.0481 - val_out_recon_loss: 0.0393 - val_out_caps_acc: 0.9532\n",
            "Epoch 5/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0565 - out_caps_loss: 0.0565 - out_recon_loss: 0.0300 - out_caps_acc: 0.9452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0507 - out_caps_loss: 0.0506 - out_recon_loss: 0.0304 - out_caps_acc: 0.9503"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0510 - out_caps_loss: 0.0510 - out_recon_loss: 0.0306 - out_caps_acc: 0.9503 - val_loss: 0.0462 - val_out_caps_loss: 0.0462 - val_out_recon_loss: 0.0389 - val_out_caps_acc: 0.9549\n",
            "8\n",
            "Epoch 1/5\n",
            " 157/1120 [===>..........................] - ETA: 4:20 - loss: 0.0485 - out_caps_loss: 0.0485 - out_recon_loss: 0.0317 - out_caps_acc: 0.9537"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 865/1120 [======================>.......] - ETA: 1:07 - loss: 0.0507 - out_caps_loss: 0.0507 - out_recon_loss: 0.0306 - out_caps_acc: 0.9514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 310s 277ms/step - loss: 0.0516 - out_caps_loss: 0.0516 - out_recon_loss: 0.0305 - out_caps_acc: 0.9503 - val_loss: 0.0520 - val_out_caps_loss: 0.0520 - val_out_recon_loss: 0.0389 - val_out_caps_acc: 0.9505\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:10 - loss: 0.0485 - out_caps_loss: 0.0485 - out_recon_loss: 0.0307 - out_caps_acc: 0.9528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:06 - loss: 0.0494 - out_caps_loss: 0.0494 - out_recon_loss: 0.0304 - out_caps_acc: 0.9521"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0510 - out_caps_loss: 0.0510 - out_recon_loss: 0.0305 - out_caps_acc: 0.9509 - val_loss: 0.0576 - val_out_caps_loss: 0.0576 - val_out_recon_loss: 0.0392 - val_out_caps_acc: 0.9448\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:09 - loss: 0.0465 - out_caps_loss: 0.0465 - out_recon_loss: 0.0301 - out_caps_acc: 0.9562"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0489 - out_caps_loss: 0.0489 - out_recon_loss: 0.0302 - out_caps_acc: 0.9533"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 309s 276ms/step - loss: 0.0492 - out_caps_loss: 0.0492 - out_recon_loss: 0.0303 - out_caps_acc: 0.9533 - val_loss: 0.0453 - val_out_caps_loss: 0.0453 - val_out_recon_loss: 0.0393 - val_out_caps_acc: 0.9564\n",
            "Epoch 4/5\n",
            " 160/1120 [===>..........................] - ETA: 4:10 - loss: 0.0498 - out_caps_loss: 0.0498 - out_recon_loss: 0.0298 - out_caps_acc: 0.9534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:06 - loss: 0.0487 - out_caps_loss: 0.0487 - out_recon_loss: 0.0302 - out_caps_acc: 0.9534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 309s 276ms/step - loss: 0.0489 - out_caps_loss: 0.0489 - out_recon_loss: 0.0303 - out_caps_acc: 0.9531 - val_loss: 0.0562 - val_out_caps_loss: 0.0562 - val_out_recon_loss: 0.0391 - val_out_caps_acc: 0.9454\n",
            "Epoch 5/5\n",
            " 159/1120 [===>..........................] - ETA: 4:10 - loss: 0.0497 - out_caps_loss: 0.0497 - out_recon_loss: 0.0307 - out_caps_acc: 0.9518"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:06 - loss: 0.0498 - out_caps_loss: 0.0498 - out_recon_loss: 0.0303 - out_caps_acc: 0.9529"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 309s 276ms/step - loss: 0.0500 - out_caps_loss: 0.0500 - out_recon_loss: 0.0302 - out_caps_acc: 0.9527 - val_loss: 0.0502 - val_out_caps_loss: 0.0502 - val_out_recon_loss: 0.0388 - val_out_caps_acc: 0.9527\n",
            "9\n",
            "Epoch 1/5\n",
            " 157/1120 [===>..........................] - ETA: 4:20 - loss: 0.0493 - out_caps_loss: 0.0493 - out_recon_loss: 0.0307 - out_caps_acc: 0.9534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 865/1120 [======================>.......] - ETA: 1:06 - loss: 0.0481 - out_caps_loss: 0.0481 - out_recon_loss: 0.0302 - out_caps_acc: 0.9542"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 309s 276ms/step - loss: 0.0487 - out_caps_loss: 0.0487 - out_recon_loss: 0.0301 - out_caps_acc: 0.9536 - val_loss: 0.0533 - val_out_caps_loss: 0.0533 - val_out_recon_loss: 0.0388 - val_out_caps_acc: 0.9498\n",
            "Epoch 2/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0487 - out_caps_loss: 0.0487 - out_recon_loss: 0.0296 - out_caps_acc: 0.9540"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0493 - out_caps_loss: 0.0492 - out_recon_loss: 0.0303 - out_caps_acc: 0.9524"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0490 - out_caps_loss: 0.0489 - out_recon_loss: 0.0302 - out_caps_acc: 0.9525 - val_loss: 0.0512 - val_out_caps_loss: 0.0512 - val_out_recon_loss: 0.0388 - val_out_caps_acc: 0.9508\n",
            "Epoch 3/5\n",
            " 160/1120 [===>..........................] - ETA: 4:09 - loss: 0.0456 - out_caps_loss: 0.0456 - out_recon_loss: 0.0304 - out_caps_acc: 0.9569"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 868/1120 [======================>.......] - ETA: 1:05 - loss: 0.0477 - out_caps_loss: 0.0477 - out_recon_loss: 0.0301 - out_caps_acc: 0.9538"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 308s 275ms/step - loss: 0.0480 - out_caps_loss: 0.0480 - out_recon_loss: 0.0301 - out_caps_acc: 0.9535 - val_loss: 0.0470 - val_out_caps_loss: 0.0470 - val_out_recon_loss: 0.0387 - val_out_caps_acc: 0.9516\n",
            "Epoch 4/5\n",
            " 159/1120 [===>..........................] - ETA: 4:09 - loss: 0.0470 - out_caps_loss: 0.0469 - out_recon_loss: 0.0302 - out_caps_acc: 0.9545"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0469 - out_caps_loss: 0.0469 - out_recon_loss: 0.0301 - out_caps_acc: 0.9556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0474 - out_caps_loss: 0.0474 - out_recon_loss: 0.0301 - out_caps_acc: 0.9551 - val_loss: 0.0462 - val_out_caps_loss: 0.0462 - val_out_recon_loss: 0.0390 - val_out_caps_acc: 0.9565\n",
            "Epoch 5/5\n",
            " 159/1120 [===>..........................] - ETA: 4:07 - loss: 0.0467 - out_caps_loss: 0.0466 - out_recon_loss: 0.0304 - out_caps_acc: 0.9553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 867/1120 [======================>.......] - ETA: 1:05 - loss: 0.0477 - out_caps_loss: 0.0477 - out_recon_loss: 0.0299 - out_caps_acc: 0.9547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1120/1120 [==============================] - 307s 274ms/step - loss: 0.0475 - out_caps_loss: 0.0475 - out_recon_loss: 0.0300 - out_caps_acc: 0.9549 - val_loss: 0.0518 - val_out_caps_loss: 0.0518 - val_out_recon_loss: 0.0391 - val_out_caps_acc: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nIXW354oIchq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finally we get the test resuls.**"
      ]
    },
    {
      "metadata": {
        "id": "qPvALQPqIb9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with h5py.File('drive/Datasets/testdata28.h5', 'r') as hf:\n",
        "    data_test = hf['Images'][:]\n",
        "    img_id = hf['Id'][:]\n",
        "\n",
        "y_pred, _ = model.predict([data_test, \n",
        "                           np.zeros((data_test.shape[0],10))], # empty values for the second vector \n",
        "                           batch_size = 32, verbose = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2pIrVixJ-IQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred,1)\n",
        "with open('submission.csv', 'w') as out_file:\n",
        "    out_file.write('ImageId,Label\\n')\n",
        "    for i in range(len(y_pred)):\n",
        "        out_file.write('%d,%d\\n' % (img_id[i], y_pred[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8iGvMhmSvOgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ef8875d0-1202-4599-9ed6-7875d70b110b"
      },
      "cell_type": "code",
      "source": [
        "#@title Author\n",
        "\n",
        "%%html\n",
        "<html>\n",
        "<head>\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "<style>\n",
        "img {\n",
        "  float: left;\n",
        "  align: left;\n",
        "  border-radius: 50%;\n",
        "}\n",
        "div.container {\n",
        "    width: 60%;\n",
        "    align-content: left;\n",
        "}\n",
        "div.name {\n",
        "    font-style: bold;\n",
        "    text-align: center;\n",
        "    font-size: 300%;\n",
        "}\n",
        "div.hobbies {\n",
        "    text-align: center;\n",
        "    color: #FF9900;\n",
        "    size: 60%;\n",
        "}\n",
        "div.edu {\n",
        "    padding-top: 10px;\n",
        "    text-align: center;\n",
        "    font-style: italic;\n",
        "    color : Gray;\n",
        "}\n",
        "div.contact {\n",
        "    padding-top: 15px;\n",
        "    text-align: center;\n",
        "    size: 80%;\n",
        "}\n",
        "div.quote {\n",
        "    font-style: italic;\n",
        "    text-align: center;\n",
        "    font-size: 120%;\n",
        "    color: Gray;\n",
        "    padding-top: 30px;\n",
        "}\n",
        "    \n",
        "    \n",
        "</style>\n",
        "</head>\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
        "<body>\n",
        "    \n",
        "    <img src=https://drive.google.com/uc?id=1IWQEbXsOl6FpaPssexnxqA_xNDC3HRu1 style=\"width:200px;height:200px;\">\n",
        "    <div class=\"container\">\n",
        "        <div class=\"name\">Samiul Alam</div>\n",
        "        <div class = \"hobbies\">AI Enthusiast </div>\n",
        "        <div class = \"edu\">Graduate, Bangladesh University of Engineering And Technology </div>\n",
        "        <div class = \"contact\"><i class=\"fa fa-github\"></i> samiul272 | <i class=\"fa fa-linkedin-square\"> samiul-alam  | </i> <i class=\"fa fa-skype\"> samiul272 </i> </div>\n",
        "        <div class=\"quote\">\"Perpetually Convalescent: Learning and Evolving\" </div> \n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head>\n",
              "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
              "<style>\n",
              "img {\n",
              "  float: left;\n",
              "  align: left;\n",
              "  border-radius: 50%;\n",
              "}\n",
              "div.container {\n",
              "    width: 60%;\n",
              "    align-content: left;\n",
              "}\n",
              "div.name {\n",
              "    font-style: bold;\n",
              "    text-align: center;\n",
              "    font-size: 300%;\n",
              "}\n",
              "div.hobbies {\n",
              "    text-align: center;\n",
              "    color: #FF9900;\n",
              "    size: 60%;\n",
              "}\n",
              "div.edu {\n",
              "    padding-top: 10px;\n",
              "    text-align: center;\n",
              "    font-style: italic;\n",
              "    color : Gray;\n",
              "}\n",
              "div.contact {\n",
              "    padding-top: 15px;\n",
              "    text-align: center;\n",
              "    size: 80%;\n",
              "}\n",
              "div.quote {\n",
              "    font-style: italic;\n",
              "    text-align: center;\n",
              "    font-size: 120%;\n",
              "    color: Gray;\n",
              "    padding-top: 30px;\n",
              "}\n",
              "    \n",
              "    \n",
              "</style>\n",
              "</head>\n",
              "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
              "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
              "<body>\n",
              "    \n",
              "    <img src=https://drive.google.com/uc?id=1IWQEbXsOl6FpaPssexnxqA_xNDC3HRu1 style=\"width:200px;height:200px;\">\n",
              "    <div class=\"container\">\n",
              "        <div class=\"name\">Samiul Alam</div>\n",
              "        <div class = \"hobbies\">AI Enthusiast </div>\n",
              "        <div class = \"edu\">Graduate, Bangladesh University of Engineering And Technology </div>\n",
              "        <div class = \"contact\"><i class=\"fa fa-github\"></i> samiul272 | <i class=\"fa fa-linkedin-square\"> samiul-alam  | </i> <i class=\"fa fa-skype\"> samiul272 </i> </div>\n",
              "        <div class=\"quote\">\"Perpetually Convalescent: Learning and Evolving\" </div> \n",
              "    </div>\n",
              "</body>\n",
              "</html>\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}